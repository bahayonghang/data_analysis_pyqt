#!/usr/bin/env python3
"""
ä»»åŠ¡13.2: å®Œæ•´å·¥ä½œæµé›†æˆæµ‹è¯•

æµ‹è¯•ç«¯åˆ°ç«¯çš„æ•°æ®åˆ†æå·¥ä½œæµï¼š
1. æ–‡ä»¶æ ¼å¼å…¼å®¹æ€§æµ‹è¯•
2. å®Œæ•´åˆ†ææµç¨‹æµ‹è¯•
3. å¯¼å‡ºåŠŸèƒ½é›†æˆæµ‹è¯•
4. å·¥ä½œæµç³»ç»Ÿé›†æˆæµ‹è¯•
5. æ€§èƒ½åŸºå‡†æµ‹è¯•
"""

import sys
import unittest
import tempfile
import shutil
import time
import asyncio
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime
import json

# å¯¼å…¥æµ‹è¯•é…ç½®
sys.path.insert(0, str(Path(__file__).parent))
from test_config import TestConfig, TestDataGenerator, TestAssertions

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))


class TestFileFormatCompatibility(unittest.TestCase):
    """æµ‹è¯•æ–‡ä»¶æ ¼å¼å…¼å®¹æ€§"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        TestConfig.setup()
    
    def tearDown(self):
        """æµ‹è¯•æ¸…ç†"""
        TestConfig.teardown()
    
    def test_csv_file_processing(self):
        """æµ‹è¯•CSVæ–‡ä»¶å¤„ç†"""
        if not TestConfig.CSV_FILE or not TestConfig.CSV_FILE.exists():
            self.skipTest("CSVæµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨")
        
        try:
            # æµ‹è¯•æ–‡ä»¶è¯»å–
            df = pd.read_csv(TestConfig.CSV_FILE)
            TestAssertions.assert_dataframe_valid(df, min_rows=10)
            
            # éªŒè¯æ•°æ®å†…å®¹
            self.assertIn('datetime', df.columns, "åº”åŒ…å«datetimeåˆ—")
            self.assertIn('temperature', df.columns, "åº”åŒ…å«temperatureåˆ—")
            self.assertTrue(len(df) > 100, f"æ•°æ®è¡Œæ•°åº”å¤§äº100ï¼Œå®é™…: {len(df)}")
            
            print(f"âœ… CSVæ–‡ä»¶å¤„ç†æµ‹è¯•é€šè¿‡: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
            
        except Exception as e:
            self.fail(f"CSVæ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
    
    def test_excel_file_processing(self):
        """æµ‹è¯•Excelæ–‡ä»¶å¤„ç†"""
        if not TestConfig.EXCEL_FILE or not TestConfig.EXCEL_FILE.exists():
            self.skipTest("Excelæµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨")
        
        try:
            # æµ‹è¯•Excelè¯»å–
            df = pd.read_excel(TestConfig.EXCEL_FILE)
            TestAssertions.assert_dataframe_valid(df, min_rows=10)
            
            # éªŒè¯æ•°æ®ç±»å‹ä¸€è‡´æ€§
            self.assertTrue(df['temperature'].dtype in [np.float64, np.int64], 
                           f"temperatureåˆ—ç±»å‹é”™è¯¯: {df['temperature'].dtype}")
            
            print(f"âœ… Excelæ–‡ä»¶å¤„ç†æµ‹è¯•é€šè¿‡: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
            
        except ImportError:
            self.skipTest("openpyxlæœªå®‰è£…ï¼Œè·³è¿‡Excelæµ‹è¯•")
        except Exception as e:
            self.fail(f"Excelæ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
    
    def test_parquet_file_processing(self):
        """æµ‹è¯•Parquetæ–‡ä»¶å¤„ç†"""
        if not TestConfig.PARQUET_FILE or not TestConfig.PARQUET_FILE.exists():
            self.skipTest("Parquetæµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨")
        
        try:
            # æµ‹è¯•Parquetè¯»å–
            df = pd.read_parquet(TestConfig.PARQUET_FILE)
            TestAssertions.assert_dataframe_valid(df, min_rows=10)
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            self.assertFalse(df.empty, "Parquetæ–‡ä»¶ä¸åº”ä¸ºç©º")
            
            print(f"âœ… Parquetæ–‡ä»¶å¤„ç†æµ‹è¯•é€šè¿‡: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
            
        except ImportError:
            self.skipTest("pyarrowæœªå®‰è£…ï¼Œè·³è¿‡Parquetæµ‹è¯•")
        except Exception as e:
            self.fail(f"Parquetæ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
    
    def test_invalid_file_handling(self):
        """æµ‹è¯•æ— æ•ˆæ–‡ä»¶å¤„ç†"""
        if not TestConfig.INVALID_FILE or not TestConfig.INVALID_FILE.exists():
            self.skipTest("æ— æ•ˆæµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æµ‹è¯•æ— æ•ˆæ–‡ä»¶åº”è¯¥æ­£ç¡®å¤„ç†é”™è¯¯
        try:
            df = pd.read_csv(TestConfig.INVALID_FILE)
            # å¦‚æœèƒ½è¯»å–ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºç©ºæˆ–æ— æ•ˆ
            if not df.empty:
                self.fail("æ— æ•ˆæ–‡ä»¶ä¸åº”è¯¥è¢«æˆåŠŸè§£æ")
        except Exception:
            # æœŸæœ›å‡ºç°å¼‚å¸¸
            print("âœ… æ— æ•ˆæ–‡ä»¶å¤„ç†æµ‹è¯•é€šè¿‡: æ­£ç¡®è¯†åˆ«å¹¶å¤„ç†äº†æ— æ•ˆæ–‡ä»¶")


class TestCompleteAnalysisWorkflow(unittest.TestCase):
    """æµ‹è¯•å®Œæ•´åˆ†æå·¥ä½œæµ"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        TestConfig.setup()
    
    def tearDown(self):
        """æµ‹è¯•æ¸…ç†"""
        TestConfig.teardown()
    
    def test_end_to_end_analysis(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯åˆ†ææµç¨‹"""
        if not TestConfig.CSV_FILE or not TestConfig.CSV_FILE.exists():
            self.skipTest("æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        try:
            # æ­¥éª¤1: æ•°æ®åŠ è½½
            df = pd.read_csv(TestConfig.CSV_FILE)
            self.assertIsNotNone(df)
            self.assertTrue(len(df) > 0)
            print(f"âœ… æ­¥éª¤1: æ•°æ®åŠ è½½æˆåŠŸ - {len(df)} è¡Œ")
            
            # æ­¥éª¤2: åŸºæœ¬ç»Ÿè®¡åˆ†æ
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            if len(numeric_columns) > 0:
                stats = df[numeric_columns].describe()
                self.assertIsNotNone(stats)
                print(f"âœ… æ­¥éª¤2: æè¿°æ€§ç»Ÿè®¡å®Œæˆ - {len(numeric_columns)} ä¸ªæ•°å€¼åˆ—")
            
            # æ­¥éª¤3: ç›¸å…³æ€§åˆ†æ
            if len(numeric_columns) > 1:
                corr_matrix = df[numeric_columns].corr()
                self.assertEqual(corr_matrix.shape[0], corr_matrix.shape[1])
                print(f"âœ… æ­¥éª¤3: ç›¸å…³æ€§åˆ†æå®Œæˆ - {corr_matrix.shape[0]}x{corr_matrix.shape[1]} çŸ©é˜µ")
            
            # æ­¥éª¤4: å¼‚å¸¸å€¼æ£€æµ‹
            for col in numeric_columns:
                z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())
                outliers = df[z_scores > 3]
                outlier_count = len(outliers)
                print(f"âœ… æ­¥éª¤4: {col} å¼‚å¸¸å€¼æ£€æµ‹å®Œæˆ - å‘ç° {outlier_count} ä¸ªå¼‚å¸¸å€¼")
            
            # æ­¥éª¤5: æ•°æ®å¯¼å‡ºæµ‹è¯•
            output_file = TestConfig.TEMP_DATA_DIR / "analysis_result.csv"
            df.to_csv(output_file, index=False)
            TestAssertions.assert_file_exists(output_file)
            print("âœ… æ­¥éª¤5: æ•°æ®å¯¼å‡ºæˆåŠŸ")
            
            print("ğŸ‰ ç«¯åˆ°ç«¯åˆ†ææµç¨‹å®Œæ•´æµ‹è¯•é€šè¿‡ï¼")
            
        except Exception as e:
            self.fail(f"ç«¯åˆ°ç«¯åˆ†ææµç¨‹å¤±è´¥: {e}")
    
    def test_time_series_analysis_workflow(self):
        """æµ‹è¯•æ—¶é—´åºåˆ—åˆ†æå·¥ä½œæµ"""
        try:
            # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
            ts_df = TestDataGenerator.create_time_series_dataframe(500)
            
            # æ—¶é—´åˆ—æ£€æµ‹
            time_columns = []
            for col in ts_df.columns:
                if ts_df[col].dtype.name.startswith('datetime'):
                    time_columns.append(col)
            
            self.assertTrue(len(time_columns) > 0, "åº”è¯¥æ£€æµ‹åˆ°æ—¶é—´åˆ—")
            print(f"âœ… æ—¶é—´åˆ—æ£€æµ‹: å‘ç° {len(time_columns)} ä¸ªæ—¶é—´åˆ—")
            
            # åŸºç¡€æ—¶é—´åºåˆ—ç»Ÿè®¡
            time_col = time_columns[0]
            value_col = 'value'
            
            if value_col in ts_df.columns:
                # è®¡ç®—åŸºæœ¬ç»Ÿè®¡
                mean_value = ts_df[value_col].mean()
                std_value = ts_df[value_col].std()
                
                self.assertIsNotNone(mean_value)
                self.assertIsNotNone(std_value)
                print(f"âœ… æ—¶é—´åºåˆ—ç»Ÿè®¡: å‡å€¼={mean_value:.2f}, æ ‡å‡†å·®={std_value:.2f}")
            
            print("âœ… æ—¶é—´åºåˆ—åˆ†æå·¥ä½œæµæµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            self.fail(f"æ—¶é—´åºåˆ—åˆ†æå·¥ä½œæµå¤±è´¥: {e}")


class TestExportIntegration(unittest.TestCase):
    """æµ‹è¯•å¯¼å‡ºåŠŸèƒ½é›†æˆ"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        TestConfig.setup()
    
    def tearDown(self):
        """æµ‹è¯•æ¸…ç†"""
        TestConfig.teardown()
    
    def test_multi_format_export(self):
        """æµ‹è¯•å¤šæ ¼å¼å¯¼å‡º"""
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            df = TestDataGenerator.create_simple_dataframe(100)
            
            # æµ‹è¯•CSVå¯¼å‡º
            csv_file = TestConfig.TEMP_DATA_DIR / "export_test.csv"
            df.to_csv(csv_file, index=False)
            TestAssertions.assert_file_exists(csv_file)
            
            # éªŒè¯å¯¼å‡ºæ–‡ä»¶å†…å®¹
            exported_df = pd.read_csv(csv_file)
            self.assertEqual(len(exported_df), len(df))
            print("âœ… CSVå¯¼å‡ºæµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•JSONå¯¼å‡º
            json_file = TestConfig.TEMP_DATA_DIR / "export_test.json"
            df.to_json(json_file, orient='records')
            TestAssertions.assert_file_exists(json_file)
            
            # éªŒè¯JSONå†…å®¹
            with open(json_file, 'r') as f:
                json_data = json.load(f)
            self.assertEqual(len(json_data), len(df))
            print("âœ… JSONå¯¼å‡ºæµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•Excelå¯¼å‡ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                excel_file = TestConfig.TEMP_DATA_DIR / "export_test.xlsx"
                df.to_excel(excel_file, index=False)
                TestAssertions.assert_file_exists(excel_file)
                print("âœ… Excelå¯¼å‡ºæµ‹è¯•é€šè¿‡")
            except ImportError:
                print("âš ï¸ Excelå¯¼å‡ºè·³è¿‡: openpyxlæœªå®‰è£…")
            
            print("âœ… å¤šæ ¼å¼å¯¼å‡ºé›†æˆæµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            self.fail(f"å¤šæ ¼å¼å¯¼å‡ºæµ‹è¯•å¤±è´¥: {e}")
    
    def test_chart_export_integration(self):
        """æµ‹è¯•å›¾è¡¨å¯¼å‡ºé›†æˆ"""
        try:
            import matplotlib.pyplot as plt
            
            # åˆ›å»ºæµ‹è¯•å›¾è¡¨
            fig, ax = plt.subplots(figsize=(8, 6))
            x = np.linspace(0, 10, 100)
            y = np.sin(x)
            ax.plot(x, y, label='sin(x)')
            ax.set_title('æµ‹è¯•å›¾è¡¨')
            ax.legend()
            
            # æµ‹è¯•PNGå¯¼å‡º
            png_file = TestConfig.TEMP_DATA_DIR / "test_chart.png"
            fig.savefig(png_file, dpi=150, bbox_inches='tight')
            TestAssertions.assert_file_exists(png_file)
            print("âœ… PNGå›¾è¡¨å¯¼å‡ºæµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•SVGå¯¼å‡º
            svg_file = TestConfig.TEMP_DATA_DIR / "test_chart.svg"
            fig.savefig(svg_file, format='svg', bbox_inches='tight')
            TestAssertions.assert_file_exists(svg_file)
            print("âœ… SVGå›¾è¡¨å¯¼å‡ºæµ‹è¯•é€šè¿‡")
            
            plt.close(fig)
            print("âœ… å›¾è¡¨å¯¼å‡ºé›†æˆæµ‹è¯•é€šè¿‡")
            
        except ImportError:
            self.skipTest("matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å›¾è¡¨å¯¼å‡ºæµ‹è¯•")
        except Exception as e:
            self.fail(f"å›¾è¡¨å¯¼å‡ºæµ‹è¯•å¤±è´¥: {e}")


class TestWorkflowSystemIntegration(unittest.TestCase):
    """æµ‹è¯•å·¥ä½œæµç³»ç»Ÿé›†æˆ"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        TestConfig.setup()
    
    def tearDown(self):
        """æµ‹è¯•æ¸…ç†"""
        TestConfig.teardown()
    
    def test_workflow_state_management(self):
        """æµ‹è¯•å·¥ä½œæµçŠ¶æ€ç®¡ç†"""
        try:
            from src.workflow import WorkflowIntegrator, WorkflowState, WorkflowContext
            
            # åˆ›å»ºå·¥ä½œæµé›†æˆå™¨
            integrator = WorkflowIntegrator()
            
            # åˆ›å»ºå·¥ä½œæµä¸Šä¸‹æ–‡
            context = WorkflowContext()
            self.assertEqual(context.current_state, WorkflowState.IDLE)
            
            # æµ‹è¯•çŠ¶æ€å˜æ›´
            context.current_state = WorkflowState.ANALYZING
            self.assertEqual(context.current_state, WorkflowState.ANALYZING)
            self.assertTrue(context.is_active)
            
            # æµ‹è¯•å®ŒæˆçŠ¶æ€
            context.current_state = WorkflowState.COMPLETED
            context.completed_at = datetime.now()
            self.assertFalse(context.is_active)
            self.assertIsNotNone(context.duration)
            
            integrator.cleanup()
            print("âœ… å·¥ä½œæµçŠ¶æ€ç®¡ç†æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            self.fail(f"å·¥ä½œæµçŠ¶æ€ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
    
    def test_performance_optimization_integration(self):
        """æµ‹è¯•æ€§èƒ½ä¼˜åŒ–é›†æˆ"""
        try:
            from src.workflow import PerformanceOptimizer, OptimizationStrategy
            
            # åˆ›å»ºæ€§èƒ½ä¼˜åŒ–å™¨
            optimizer = PerformanceOptimizer()
            
            # æµ‹è¯•ä¼˜åŒ–ç­–ç•¥è®¾ç½®
            strategies = [
                OptimizationStrategy.BALANCED,
                OptimizationStrategy.MEMORY_AGGRESSIVE,
                OptimizationStrategy.RESPONSIVE
            ]
            
            for strategy in strategies:
                optimizer.set_optimization_strategy(strategy)
                self.assertEqual(optimizer.current_strategy, strategy)
            
            # æµ‹è¯•UIä¼˜åŒ–å»ºè®®
            recommendations = optimizer.optimize_ui_rendering(50)
            self.assertIsInstance(recommendations, dict)
            self.assertIn('batch_updates', recommendations)
            
            # æµ‹è¯•æ€§èƒ½æ‘˜è¦
            summary = optimizer.get_performance_summary()
            self.assertIsInstance(summary, dict)
            
            optimizer.cleanup()
            print("âœ… æ€§èƒ½ä¼˜åŒ–é›†æˆæµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            self.fail(f"æ€§èƒ½ä¼˜åŒ–é›†æˆæµ‹è¯•å¤±è´¥: {e}")


class TestPerformanceBenchmarks(unittest.TestCase):
    """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        TestConfig.setup()
    
    def tearDown(self):
        """æµ‹è¯•æ¸…ç†"""
        TestConfig.teardown()
    
    def test_data_loading_performance(self):
        """æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½"""
        if not TestConfig.CSV_FILE or not TestConfig.CSV_FILE.exists():
            self.skipTest("æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        try:
            # åŸºå‡†æµ‹è¯•ï¼šæ•°æ®åŠ è½½æ—¶é—´
            start_time = time.time()
            df = pd.read_csv(TestConfig.CSV_FILE)
            load_time = time.time() - start_time
            
            # æ€§èƒ½æ–­è¨€ï¼ˆåŠ è½½æ—¶é—´åº”è¯¥åˆç†ï¼‰
            self.assertLess(load_time, 5.0, f"æ•°æ®åŠ è½½æ—¶é—´è¿‡é•¿: {load_time:.2f}ç§’")
            
            # å†…å­˜ä½¿ç”¨æ£€æŸ¥
            memory_usage = df.memory_usage(deep=True).sum() / 1024 / 1024  # MB
            self.assertLess(memory_usage, 100, f"å†…å­˜ä½¿ç”¨è¿‡å¤š: {memory_usage:.2f}MB")
            
            print(f"âœ… æ•°æ®åŠ è½½æ€§èƒ½æµ‹è¯•é€šè¿‡: {load_time:.3f}ç§’, {memory_usage:.2f}MB")
            
        except Exception as e:
            self.fail(f"æ•°æ®åŠ è½½æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    def test_analysis_performance(self):
        """æµ‹è¯•åˆ†ææ€§èƒ½"""
        try:
            # åˆ›å»ºå¤§æ•°æ®é›†è¿›è¡Œæ€§èƒ½æµ‹è¯•
            large_df = TestDataGenerator.create_correlation_dataframe(10000)
            
            # åŸºå‡†æµ‹è¯•ï¼šæè¿°æ€§ç»Ÿè®¡
            start_time = time.time()
            stats = large_df.describe()
            stats_time = time.time() - start_time
            
            self.assertLess(stats_time, 2.0, f"æè¿°æ€§ç»Ÿè®¡æ—¶é—´è¿‡é•¿: {stats_time:.2f}ç§’")
            
            # åŸºå‡†æµ‹è¯•ï¼šç›¸å…³æ€§åˆ†æ
            start_time = time.time()
            corr_matrix = large_df.select_dtypes(include=[np.number]).corr()
            corr_time = time.time() - start_time
            
            self.assertLess(corr_time, 3.0, f"ç›¸å…³æ€§åˆ†ææ—¶é—´è¿‡é•¿: {corr_time:.2f}ç§’")
            
            print(f"âœ… åˆ†ææ€§èƒ½æµ‹è¯•é€šè¿‡: ç»Ÿè®¡={stats_time:.3f}s, ç›¸å…³æ€§={corr_time:.3f}s")
            
        except Exception as e:
            self.fail(f"åˆ†ææ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    def test_export_performance(self):
        """æµ‹è¯•å¯¼å‡ºæ€§èƒ½"""
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            df = TestDataGenerator.create_simple_dataframe(5000)
            
            # åŸºå‡†æµ‹è¯•ï¼šCSVå¯¼å‡º
            csv_file = TestConfig.TEMP_DATA_DIR / "perf_test.csv"
            start_time = time.time()
            df.to_csv(csv_file, index=False)
            csv_time = time.time() - start_time
            
            self.assertLess(csv_time, 2.0, f"CSVå¯¼å‡ºæ—¶é—´è¿‡é•¿: {csv_time:.2f}ç§’")
            TestAssertions.assert_file_exists(csv_file)
            
            # åŸºå‡†æµ‹è¯•ï¼šJSONå¯¼å‡º
            json_file = TestConfig.TEMP_DATA_DIR / "perf_test.json"
            start_time = time.time()
            df.to_json(json_file, orient='records')
            json_time = time.time() - start_time
            
            self.assertLess(json_time, 3.0, f"JSONå¯¼å‡ºæ—¶é—´è¿‡é•¿: {json_time:.2f}ç§’")
            TestAssertions.assert_file_exists(json_file)
            
            print(f"âœ… å¯¼å‡ºæ€§èƒ½æµ‹è¯•é€šè¿‡: CSV={csv_time:.3f}s, JSON={json_time:.3f}s")
            
        except Exception as e:
            self.fail(f"å¯¼å‡ºæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")


class TestRegressionSuite(unittest.TestCase):
    """å›å½’æµ‹è¯•å¥—ä»¶"""
    
    def test_data_consistency(self):
        """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§"""
        try:
            # åˆ›å»ºç›¸åŒç§å­çš„æ•°æ®ï¼Œåº”è¯¥äº§ç”Ÿä¸€è‡´ç»“æœ
            np.random.seed(12345)
            df1 = TestDataGenerator.create_simple_dataframe(100)
            
            np.random.seed(12345)
            df2 = TestDataGenerator.create_simple_dataframe(100)
            
            # éªŒè¯æ•°æ®ä¸€è‡´æ€§
            pd.testing.assert_frame_equal(df1, df2)
            print("âœ… æ•°æ®ä¸€è‡´æ€§å›å½’æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            self.fail(f"æ•°æ®ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {e}")
    
    def test_statistical_consistency(self):
        """æµ‹è¯•ç»Ÿè®¡è®¡ç®—ä¸€è‡´æ€§"""
        try:
            # åˆ›å»ºå·²çŸ¥ç»Ÿè®¡ç‰¹æ€§çš„æ•°æ®
            np.random.seed(42)
            data = np.random.normal(100, 15, 1000)
            df = pd.DataFrame({'value': data})
            
            # å¤šæ¬¡è®¡ç®—åº”è¯¥äº§ç”Ÿç›¸åŒç»“æœ
            stats1 = df.describe()
            stats2 = df.describe()
            
            pd.testing.assert_frame_equal(stats1, stats2)
            print("âœ… ç»Ÿè®¡è®¡ç®—ä¸€è‡´æ€§å›å½’æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            self.fail(f"ç»Ÿè®¡è®¡ç®—ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {e}")


def run_integration_tests():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    print("\nğŸ”— å¼€å§‹å®Œæ•´å·¥ä½œæµé›†æˆæµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestFileFormatCompatibility,
        TestCompleteAnalysisWorkflow,
        TestExportIntegration,
        TestWorkflowSystemIntegration,
        TestPerformanceBenchmarks,
        TestRegressionSuite
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # ç»Ÿè®¡ç»“æœ
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    skipped = len(result.skipped) if hasattr(result, 'skipped') else 0
    passed = total_tests - failures - errors - skipped
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š é›†æˆæµ‹è¯•ç»“æœæ±‡æ€»:")
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"é€šè¿‡æµ‹è¯•: {passed}")
    print(f"å¤±è´¥æµ‹è¯•: {failures}")
    print(f"é”™è¯¯æµ‹è¯•: {errors}")
    print(f"è·³è¿‡æµ‹è¯•: {skipped}")
    print(f"é€šè¿‡ç‡: {passed/total_tests*100:.1f}%")
    
    if failures > 0:
        print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, error in result.failures:
            print(f"  - {test}: {error.split('AssertionError:')[-1].strip()}")
    
    if errors > 0:
        print(f"\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, error in result.errors:
            print(f"  - {test}: {error.split('Exception:')[-1].strip()}")
    
    if passed == total_tests:
        print("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°")
        return False


if __name__ == "__main__":
    success = run_integration_tests()
    sys.exit(0 if success else 1)